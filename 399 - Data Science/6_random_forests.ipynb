{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Andrew_Letz_rf_assignment_w19.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"_zyEMPhCnHC_","colab_type":"text"},"cell_type":"markdown","source":["<h1>\n","<center>\n","Module 6: Random Forests\n","</center>\n","</h1>\n","<div class=h1_cell>\n","\n","You will be working with the loan table again.\n","\n","</div>"]},{"metadata":{"id":"KJT0kc6FhooT","colab_type":"code","outputId":"e6d8e2dc-bcc8-449d-a176-3dba9e717247","executionInfo":{"status":"ok","timestamp":1550451029121,"user_tz":480,"elapsed":21828,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"YRgA76lahpmR","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('/content/gdrive/My Drive/class_tables/loan_table_week4.csv', 'r') as f:\n","  loan_table = pd.read_csv(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RjDDjSE-htzN","colab_type":"code","outputId":"2da8a38e-3b0d-4d20-93db-c54232257082","executionInfo":{"status":"ok","timestamp":1550451033835,"user_tz":480,"elapsed":1254,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["!rm library_w19_week6.py"],"execution_count":3,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'library_w19_week6.py': No such file or directory\n"],"name":"stdout"}]},{"metadata":{"id":"SCblsgv0nHDB","colab_type":"code","outputId":"2dca2513-5ab3-4521-fb7f-0612b75186ca","executionInfo":{"status":"ok","timestamp":1550451038200,"user_tz":480,"elapsed":3987,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":113}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-ada2ea25-0289-4cc4-a76b-383dac32d19e\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-ada2ea25-0289-4cc4-a76b-383dac32d19e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving library_w19_week6.py to library_w19_week6.py\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'library_w19_week6.py': b'from functools import reduce\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\nfrom types import SimpleNamespace\\r\\nimport random\\r\\n\\r\\ndef predictor_case(row, pred, target):\\r\\n  case_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\r\\n  actual = row[target]\\r\\n  prediction = row[pred]\\r\\n  case = case_dict[(prediction, actual)]\\r\\n  return case\\r\\n\\r\\ndef accuracy(cases):\\r\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\r\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\r\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\r\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\r\\n    return (tp + tn) / (tp+tn+fp+fn) if (tp+tn+fp+fn) != 0 else 0\\r\\n\\r\\ndef f1(cases):\\r\\n    #the heart of the matrix\\r\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\r\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\r\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\r\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\r\\n    \\r\\n    #other measures we can derive\\r\\n    recall = 1.0*tp / (tp+fn) if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\\r\\n    precision = 1.0*tp / (tp+fp) if (tp+fp) != 0 else 0 # positive correct divided by all positive predictions made\\r\\n    \\r\\n    #now for the one we want\\r\\n    term1 = 1 / recall if recall != 0 else 0\\r\\n    term2 = 1 / precision if precision != 0 else 0\\r\\n    f1 = 2 / (term1 + term2) if term1 + term2 != 0 else 0\\r\\n    \\r\\n    return f1\\r\\n\\r\\ndef informedness(cases):\\r\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\r\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\r\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\r\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\r\\n    recall = 1.0*tp / (tp+fn) if (tp+fn) != 0 else 0  # positive correct divided by total positive in the table\\r\\n    specificty = 1.0*tn/(tn+fp) if (tn+fp) != 0 else 0 # negative correct divided by total negative in the table\\r\\n    J = (recall + specificty) - 1\\r\\n    return J\\r\\n\\r\\ndef probabilities(counts):\\r\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\r\\n    count_1 = 0 if 1 not in counts else counts[1]\\r\\n    total = count_0 + count_1\\r\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\r\\n    return probs\\r\\n\\r\\ndef gini(counts):\\r\\n    (p0,p1) = probabilities(counts)\\r\\n    sum_probs = p0**2 + p1**2\\r\\n    gini = 1 - sum_probs\\r\\n    return gini\\r\\n\\r\\ndef gig(starting_table, split_column, target_column):\\r\\n    \\r\\n    #split into two branches, i.e., two sub-tables\\r\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\r\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\r\\n    \\r\\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\r\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\r\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\r\\n    starting_counts = starting_table[target_column].value_counts() \\r\\n    \\r\\n    #compute the gini impurity for the 3 tables\\r\\n    starting_gini = gini(starting_counts)\\r\\n    true_gini = gini(true_counts)\\r\\n    false_gini = gini(false_counts)\\r\\n\\r\\n    #compute the weights\\r\\n    starting_size = len(starting_table.index)\\r\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\r\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\r\\n    \\r\\n    #wrap it up and put on a bow\\r\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\r\\n    \\r\\n    return gig\\r\\n\\r\\ndef build_pred(column, branch):\\r\\n    return lambda row: row[column] == branch\\r\\n\\r\\ndef find_best_splitter(table, choice_list, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot split empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\r\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\r\\n    return gig_sorted\\r\\n\\r\\ndef generate_table(table, conjunction):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot generate from empty table\"\\r\\n\\r\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\r\\n    return sub_table\\r\\n\\r\\ndef compute_prediction(table, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot predict from empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\r\\n\\r\\n    if 0 not in counts:\\r\\n        prediction = 1\\r\\n    elif 1 not in counts:\\r\\n        prediction = 0\\r\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\r\\n        prediction = 1\\r\\n    else:\\r\\n        prediction = 0\\r\\n\\r\\n    return prediction\\r\\n\\r\\ndef build_tree_iter(table, choices, target, hypers={} ):\\r\\n\\r\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\r\\n    assert (target in table), \"Target column not in table\"\\r\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\r\\n    \\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    \\r\\n    def iterative_build(k):\\r\\n        columns_sorted = find_best_splitter(table, choices, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n        \\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\r\\n        tree_paths = []  # add completed paths here\\r\\n        \\r\\n        while k>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\r\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n            \\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                k -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunction = path[\\'conjunction\\']\\r\\n            before_table = generate_table(table, conjunction)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return tree_paths\\r\\n\\r\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\r\\n\\r\\ndef tree_predictor(row, tree):\\r\\n    \\r\\n    #go through each path, one by one (could use a map instead of for loop?)\\r\\n    for path in tree[\\'paths\\']:\\r\\n        conjuncts = path[\\'conjunction\\']\\r\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n        if all(result):\\r\\n            return path[\\'prediction\\']\\r\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\r\\n\\r\\ndef path_id(row, tree):\\r\\n  \\r\\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\r\\n    \\r\\n    for idx,path in enumerate(tree[\\'paths\\']):\\r\\n      conjuncts = path[\\'conjunction\\']\\r\\n      result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n      if all(result):\\r\\n        return idx\\r\\n\\r\\ndef reorder_paths(table, tree):\\r\\n  pcounts = table.apply(lambda row: path_id(row, tree), axis = 1)\\r\\n  pdict = dict(pcounts.value_counts())\\r\\n  plist = [(key, pdict[key]) for key in pdict]\\r\\n  plist = sorted(plist, key = lambda tup: tup[1])[::-1]\\r\\n  \\r\\n  new_paths = []\\r\\n  for tup in plist:\\r\\n    new_paths.append(tree[\\'paths\\'][tup[0]])\\r\\n    \\r\\n  return new_paths\\r\\n\\r\\ndef produce_scores(table, tree, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef compute_training(slices, left_out):\\r\\n    training_slices = []\\r\\n    for i,slice in enumerate(slices):\\r\\n        if i == left_out:\\r\\n            continue\\r\\n        training_slices.append(slices[i])\\r\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\r\\n\\r\\ndef k_fold(table, k, target, hypers, candidate_columns):\\r\\n  \\r\\n    #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    for i in range(k-1):\\r\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n        slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef verify_unique(slices):\\r\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\r\\n    for i, a_slice in enumerate(slices[:-1]):\\r\\n        a_set = set(a_slice.index)\\r\\n        for j, b_slice in enumerate(slices[i+1:]):\\r\\n            b_set = set(b_slice.index)\\r\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\r\\n            print((i,j+i+1,int_set))\\r\\n    return None\\r\\n\\r\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\r\\n  \\r\\n    #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    total_len = len(table.index)\\r\\n    split_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    available_rows = [i for i in range(total_len)] # we will pick a random row from here\\r\\n\\r\\n    for i in range(k):\\r\\n      a_slice = pd.DataFrame(columns=table.columns)\\r\\n\\r\\n      for j in range(split_size):\\r\\n        rand_idx = random.randint(0, len(available_rows) - 1)\\r\\n        idx = available_rows[rand_idx] # which row we want to grab\\r\\n        a_slice = a_slice.append(table[idx:idx+1], ignore_index=False) # add random row to current slice\\r\\n        available_rows.remove(idx) # remove that row from the available rows\\r\\n\\r\\n      slices.append( a_slice )\\r\\n\\r\\n    for remaining_idx in available_rows: # add the remaining rows to our final slice\\r\\n      slices[len(slices) - 1] = slices[len(slices) - 1].append(table[remaining_idx:remaining_idx+1], ignore_index=False)\\r\\n      \\r\\n    verify_unique(slices)  # leaving this in here to verify it is working\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef vote_taker(row, forest):\\r\\n    votes = {0:0, 1:0}\\r\\n    for tree in forest:\\r\\n        prediction = tree_predictor(row, tree)\\r\\n        votes[prediction] += 1\\r\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\r\\n    return winner\\r\\n\\r\\ndef forest_scores(table, forest, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef forest_builder(table, column_choices, target, hypers):\\r\\n\\r\\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\r\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\r\\n\\r\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\r\\n    def iterative_build(n):\\r\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\r\\n        train = train.reset_index()\\r\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\r\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\r\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\r\\n        \\r\\n        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\\r\\n        columns_sorted = find_best_splitter(train, rcols, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n\\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\r\\n        tree_paths = []  # add completed paths here\\r\\n\\r\\n        while n>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\r\\n                rcols = random.sample(column_choices, m)  # subspace\\r\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value\\r\\n                                 }\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n\\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                n -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunct = path[\\'conjunction\\']\\r\\n            before_table = generate_table(train, conjunct)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return (tree_paths, oob_list)\\r\\n    \\r\\n    #let\\'s build a forest\\r\\n    forest = []\\r\\n    for i in range(tree_n):\\r\\n        (paths, oob) = iterative_build(k)  #always use k for now\\r\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\r\\n        \\r\\n    return forest\\r\\n'}"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"rtmSW_2BnHDF","colab_type":"code","outputId":"96edbeea-9ced-49d2-b9e5-a0a0c7e1f9f2","executionInfo":{"status":"ok","timestamp":1550451041648,"user_tz":480,"elapsed":304,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["from library_w19_week6 import *\n","\n","%who function"],"execution_count":5,"outputs":[{"output_type":"stream","text":["accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t f1\t find_best_splitter\t forest_builder\t forest_scores\t \n","generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t path_id\t predictor_case\t probabilities\t \n","produce_scores\t reorder_paths\t tree_predictor\t verify_unique\t vote_taker\t \n"],"name":"stdout"}]},{"metadata":{"scrolled":true,"id":"YnHkUajjnHDQ","colab_type":"code","outputId":"385256fe-a358-4945-9e23-83bafb9c158d","executionInfo":{"status":"ok","timestamp":1550451043493,"user_tz":480,"elapsed":330,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"cell_type":"code","source":["pd.set_option('display.max_columns', None)\n","loan_table.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Married</th>\n","      <th>Dependents</th>\n","      <th>Education</th>\n","      <th>Self_Employed</th>\n","      <th>ApplicantIncome</th>\n","      <th>CoapplicantIncome</th>\n","      <th>LoanAmount</th>\n","      <th>Loan_Amount_Term</th>\n","      <th>Credit_History</th>\n","      <th>Property_Area</th>\n","      <th>Loan_Status</th>\n","      <th>no_lam</th>\n","      <th>filled_lam</th>\n","      <th>pa_Rural</th>\n","      <th>pa_Semiurban</th>\n","      <th>pa_Urban</th>\n","      <th>pa_nan</th>\n","      <th>lam_bin</th>\n","      <th>lam_Low</th>\n","      <th>lam_Average</th>\n","      <th>lam_High</th>\n","      <th>ch_bad</th>\n","      <th>ch_good</th>\n","      <th>ch_nan</th>\n","      <th>apin_binned</th>\n","      <th>apin_low</th>\n","      <th>apin_average</th>\n","      <th>apin_high</th>\n","      <th>apin_nan</th>\n","      <th>dep_0</th>\n","      <th>dep_1</th>\n","      <th>dep_2</th>\n","      <th>dep_3+</th>\n","      <th>dep_nan</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>5849</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>146.412162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>1</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>4583</td>\n","      <td>1508.0</td>\n","      <td>128.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Rural</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>128.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>Yes</td>\n","      <td>3000</td>\n","      <td>0.0</td>\n","      <td>66.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>66.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>0</td>\n","      <td>Not Graduate</td>\n","      <td>No</td>\n","      <td>2583</td>\n","      <td>2358.0</td>\n","      <td>120.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>6000</td>\n","      <td>0.0</td>\n","      <td>141.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>141.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n","0   Male      No          0      Graduate            No             5849   \n","1   Male     Yes          1      Graduate            No             4583   \n","2   Male     Yes          0      Graduate           Yes             3000   \n","3   Male     Yes          0  Not Graduate            No             2583   \n","4   Male      No          0      Graduate            No             6000   \n","\n","   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n","0                0.0         NaN             360.0             1.0   \n","1             1508.0       128.0             360.0             1.0   \n","2                0.0        66.0             360.0             1.0   \n","3             2358.0       120.0             360.0             1.0   \n","4                0.0       141.0             360.0             1.0   \n","\n","  Property_Area  Loan_Status  no_lam  filled_lam  pa_Rural  pa_Semiurban  \\\n","0         Urban            1       1  146.412162         0             0   \n","1         Rural            0       0  128.000000         1             0   \n","2         Urban            1       0   66.000000         0             0   \n","3         Urban            1       0  120.000000         0             0   \n","4         Urban            1       0  141.000000         0             0   \n","\n","   pa_Urban  pa_nan lam_bin  lam_Low  lam_Average  lam_High  ch_bad  ch_good  \\\n","0         1       0     Low        1            0         0       0        1   \n","1         0       0     Low        1            0         0       0        1   \n","2         1       0     Low        1            0         0       0        1   \n","3         1       0     Low        1            0         0       0        1   \n","4         1       0     Low        1            0         0       0        1   \n","\n","   ch_nan apin_binned  apin_low  apin_average  apin_high  apin_nan  dep_0  \\\n","0       0         low         1             0          0         0      1   \n","1       0         low         1             0          0         0      0   \n","2       0         low         1             0          0         0      1   \n","3       0         low         1             0          0         0      1   \n","4       0         low         1             0          0         0      1   \n","\n","   dep_1  dep_2  dep_3+  dep_nan  \n","0      0      0       0        0  \n","1      1      0       0        0  \n","2      0      0       0        0  \n","3      0      0       0        0  \n","4      0      0       0        0  "]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"gVKmmwDqnHDW","colab_type":"code","outputId":"d220901f-252b-4459-f248-a23c08d7a00b","executionInfo":{"status":"ok","timestamp":1550451045667,"user_tz":480,"elapsed":337,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"cell_type":"code","source":["loan_table.columns.values"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n","       'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n","       'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n","       'Loan_Status', 'no_lam', 'filled_lam', 'pa_Rural', 'pa_Semiurban',\n","       'pa_Urban', 'pa_nan', 'lam_bin', 'lam_Low', 'lam_Average',\n","       'lam_High', 'ch_bad', 'ch_good', 'ch_nan', 'apin_binned',\n","       'apin_low', 'apin_average', 'apin_high', 'apin_nan', 'dep_0',\n","       'dep_1', 'dep_2', 'dep_3+', 'dep_nan'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"VpXRjQHtnHDa","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","1: Explore forest options (20)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","Check out the results you get from forests of size 5, 11, 17.\n","<p>\n","First, define the columns to use. I do that for you below.\n","</div>"]},{"metadata":{"id":"DNRyB8DvnHDc","colab_type":"code","colab":{}},"cell_type":"code","source":["splitter_columns = [\n","        #Dependents\n","        'dep_0', 'dep_1', 'dep_2', 'dep_3+',\n","        #ApplicantIncome\n","       'apin_low', 'apin_high', 'apin_average',\n","        #Property_Area\n","        'pa_Rural', 'pa_Semiurban','pa_Urban',\n","        #LoanAmount\n","        'lam_Low', 'lam_Average', 'lam_High',\n","        #Credit_History\n","        'ch_bad', 'ch_good']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zPLu2ub9nHDg","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h2>\n","Set seeds so get consistent results\n","</h2>\n","<p>\n","<div class=h1_cell>\n","<p>\n","\n","</div>"]},{"metadata":{"id":"W1eNjUiSnW0p","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import random\n","\n","rng = np.random.RandomState(42)  #Will pass as arg to pandas sample method\n","random.seed(2000)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iuhvnqw3nHDh","colab_type":"code","outputId":"07977fec-a869-46a3-a161-1bf2fb52bf1b","executionInfo":{"status":"ok","timestamp":1550451050601,"user_tz":480,"elapsed":451,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["forest1 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'random-state':rng})\n","len(forest1)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"-fCS27OonHDm","colab_type":"code","outputId":"d9436ad9-5626-4684-d049-9595d53c2317","executionInfo":{"status":"ok","timestamp":1550451055162,"user_tz":480,"elapsed":486,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["forest_scores(loan_table, forest1, 'Loan_Status')"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"Rjc3x2M8nHDr","colab_type":"code","outputId":"38722968-4c6f-4012-b567-8108e4e3b510","executionInfo":{"status":"ok","timestamp":1550451056645,"user_tz":480,"elapsed":690,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["forest2 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees':11, 'random-state':rng})\n","len(forest2)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"IXRcCWcpnHDx","colab_type":"code","outputId":"1f677cb1-9885-4d07-f12b-755f3cae974a","executionInfo":{"status":"ok","timestamp":1550451059620,"user_tz":480,"elapsed":484,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["forest_scores(loan_table, forest2, 'Loan_Status')"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7785016286644951, 0.8597938144329897, 0.3058599921011058]"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"I-n4Tf5bnHD2","colab_type":"code","outputId":"36774856-c198-45a2-ac0f-d87f9e3f68c2","executionInfo":{"status":"ok","timestamp":1550451062414,"user_tz":480,"elapsed":878,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["forest3 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees':17, 'random-state':rng})\n","len(forest3)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"Sh3evOrbnHD8","colab_type":"code","outputId":"15cef587-0cff-4167-e1b7-f8191864223a","executionInfo":{"status":"ok","timestamp":1550451066260,"user_tz":480,"elapsed":732,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["forest_scores(loan_table, forest3, 'Loan_Status')"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"cfoOXy5JnHEA","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","2: Implement Out of Bag testing (80)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","Last module we looked at the use of K-Folding as a means to test our trees. Random Forests give us an alternative by using out of bag testing. Using notes from the content notebook this week, find a way to do prediction using the oob idea. As reminder, the set union of all the oob lists in a forest make up the testing set. If there is a row in loan_table that is not in any oob list, that row should be omitted from the test set. Further, a tree only gets to vote on a specific row if that row is in the tree's oob list.\n","  <p>\n","  I am going to leave it to you to come up with an algorithm for doing oob testing. If you get totally stuck, I can supply hints. For grading I am looking to make sure you only use oob rows for testing and that each individual tree only votes on rows in its own oob list.\n","    <p>\n","      It is worthwhile solving this problem given something like it will likely be on next midterm.\n","</div>"]},{"metadata":{"id":"QYlMHr1RnHEK","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_oob_table(original_table, forest):\n","  # get union of all out of bag rows\n","  oob_union = []\n","  for tree in forest:\n","    oob_union = list(set(oob_union) | set(tree['oob']))\n","\n","  # create new table using unioned oob rows\n","  testing_table = original_table.loc[oob_union]\n","  testing_table = testing_table.reset_index()\n","  \n","  return testing_table\n","\n","def oob_forest_scores(table, forest, target):\n","  scratch_table = pd.DataFrame(columns=['prediction', 'actual'])\n","  \n","  # will only add a vote if a tree is supposed to vote on 'row'\n","  def oob_vote_taker(row, forest):\n","    votes = {0:0, 1:0}\n","    for tree in forest:\n","      if row['index'] not in tree['oob']: continue # check if its in the tree's oob list\n","      prediction = tree_predictor(row, tree)\n","      votes[prediction] += 1\n","    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\n","    return winner\n","  \n","  scratch_table['prediction'] = table.apply(lambda row: oob_vote_taker(row, forest), axis=1)\n","  scratch_table['actual'] = table[target]  # just copy the target column\n","  cases = scratch_table.apply(lambda row: predictor_case(row, pred='prediction', target='actual'), axis=1)\n","  vc = cases.value_counts()\n","  return [accuracy(vc), f1(vc), informedness(vc)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G9gDrRf8p1E1","colab_type":"text"},"cell_type":"markdown","source":["<h2>Check your oob testing against my results</h2>\n","\n","If you used the random seeds to build your trees, your results should be the same as mine. No randomness during oob testing."]},{"metadata":{"id":"B5PW22KtotRM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"97d40de0-dddd-45df-fb3c-b83edc10c41e","executionInfo":{"status":"ok","timestamp":1550453288353,"user_tz":480,"elapsed":336,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#whole table from above: [0.8094462540716613, 0.8764519535374868, 0.4104956556082149]\n","\n","testing_table_1 = get_oob_table(loan_table, forest1)\n","oob_forest_scores(testing_table_1, forest1, 'Loan_Status')"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7887067395264117, 0.8595641646489104, 0.39501598819333417]"]},"metadata":{"tags":[]},"execution_count":50}]},{"metadata":{"id":"NeopvaI5psYx","colab_type":"code","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wcj4Oy5vpxlW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"199bb446-fd05-4204-afd3-a13428e15134","executionInfo":{"status":"ok","timestamp":1550453291068,"user_tz":480,"elapsed":425,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#from above: [0.7785016286644951, 0.8597938144329897, 0.3058599921011058]\n","\n","testing_table_2 = get_oob_table(loan_table, forest2)\n","oob_forest_scores(testing_table_2, forest2, 'Loan_Status')"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7586206896551724, 0.8457502623294858, 0.2730153560960946]"]},"metadata":{"tags":[]},"execution_count":51}]},{"metadata":{"id":"ut4tfLw0p-k2","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"V_bnlpv-p_mm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d3d45eb4-3379-4372-f2cb-b3f754b31531","executionInfo":{"status":"ok","timestamp":1550453292886,"user_tz":480,"elapsed":774,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#from above: [0.8094462540716613, 0.8764519535374868, 0.4104956556082149]\n","\n","testing_table_3 = get_oob_table(loan_table, forest3)\n","oob_forest_scores(testing_table_3, forest3, 'Loan_Status')"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7768729641693811, 0.8568443051201673, 0.32052231437598744]"]},"metadata":{"tags":[]},"execution_count":52}]},{"metadata":{"id":"9ofRzrrInfGp","colab_type":"text"},"cell_type":"markdown","source":["<h2>Not a lot of change</h2>\n","\n","Using oob testing did not affect scores much. I think we would need to work with bigger tables, e.g., the 25K shelter table, to see a difference."]},{"metadata":{"id":"pqg9TP5Cqpy8","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>Write it out</h1>\n","<div class=h1_cell>\n","\n","Did not change table but we did define new functions. Add them to your library as `!rm library_w19_week6b.py`. I added the `b` to designate functions from assignment portion of module.\n","</div>"]}]}