{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kfold_assignment_w19.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"C2pMCaZa6uPJ","colab_type":"text"},"cell_type":"markdown","source":["<h1>\n","<center>\n","Module 5: Bias-Variance and Cross-Validation\n","</center>\n","</h1>\n","<div class=h1_cell>\n","\n","You will be working with the loan table again.\n","\n","</div>"]},{"metadata":{"id":"xqGv8Swz6uPK","colab_type":"code","outputId":"01004cd8-fb07-47ae-a4e0-e0727b8e7871","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1549843020114,"user_tz":480,"elapsed":327,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"v4wxFUgC6uPO","colab_type":"code","outputId":"6e7085fa-2457-4d77-fa51-7d3567b284a6","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1549843021346,"user_tz":480,"elapsed":337,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["with open('/content/gdrive/My Drive/class_tables/loan_wrangled_week3.csv', 'r') as f:\n","  loan_table = pd.read_csv(f)\n","\n","loan_table.head(2)  #make sure it looks ok - we see the results of our week 2 wrangling"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Married</th>\n","      <th>Dependents</th>\n","      <th>Education</th>\n","      <th>Self_Employed</th>\n","      <th>ApplicantIncome</th>\n","      <th>CoapplicantIncome</th>\n","      <th>LoanAmount</th>\n","      <th>Loan_Amount_Term</th>\n","      <th>Credit_History</th>\n","      <th>...</th>\n","      <th>lam_Average</th>\n","      <th>lam_High</th>\n","      <th>ch_bad</th>\n","      <th>ch_good</th>\n","      <th>ch_nan</th>\n","      <th>apin_binned</th>\n","      <th>apin_low</th>\n","      <th>apin_average</th>\n","      <th>apin_high</th>\n","      <th>apin_nan</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>5849</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>1</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>4583</td>\n","      <td>1508.0</td>\n","      <td>128.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows Ã— 30 columns</p>\n","</div>"],"text/plain":["  Gender Married Dependents Education Self_Employed  ApplicantIncome  \\\n","0   Male      No          0  Graduate            No             5849   \n","1   Male     Yes          1  Graduate            No             4583   \n","\n","   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History    ...     \\\n","0                0.0         NaN             360.0             1.0    ...      \n","1             1508.0       128.0             360.0             1.0    ...      \n","\n","  lam_Average  lam_High  ch_bad  ch_good  ch_nan  apin_binned  apin_low  \\\n","0           0         0       0        1       0          low         1   \n","1           0         0       0        1       0          low         1   \n","\n","   apin_average apin_high  apin_nan  \n","0             0         0         0  \n","1             0         0         0  \n","\n","[2 rows x 30 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"scrolled":true,"id":"8RcFXWfj6uPa","colab_type":"code","colab":{}},"cell_type":"code","source":["pd.set_option('display.max_columns', None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xhj82RM_RAA3","colab_type":"text"},"cell_type":"markdown","source":["<h2>A couple of notes</h2>\n","I added points to assignments to give you an idea of how much of a challenge I think they are. Let me know if I am off base.\n","<p>\n","  Don't load your library yet. Finish problem 1 before importing your library."]},{"metadata":{"id":"kmKkY51gCH_F","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","1: Fix our scoring functions (30 points)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","As we defined our scoring functions in week 2, they all assume that the 4 cases have values greater than 0. But this week we will see that is not always the case. And hence you will get an error like this if you try using the scoring functions as is:\n","  <pre>\n","  KeyError: 'false_negative'\n","  </pre>\n","<p>\n","What this means is that there were no false negatives found so the key is also not found. You would find the problem in a statement like this:\n","  <pre>\n","  fn = cases['false_negative']  #key does not exist because no false negatives\n","  </pre>\n","  Your task is to fix up the 3 scoring functions so they handle cases like this. And while you are at it, make sure you never divide by 0. Once you have them working, you can add them to your library for this week. I give you some test cases to code against.\n","  <p>\n"," Important: do not import your library before (a) you have all functions below working correctly, and (b) you have replaced the old functions in your library with the new ones.\n","</div>"]},{"metadata":{"id":"QLciYNSWDF-r","colab_type":"code","colab":{}},"cell_type":"code","source":["def accuracy(cases):\n","    tp = cases['true_positive'] if 'true_positive' in cases else 0\n","    tn = cases['true_negative'] if 'true_negative' in cases else 0\n","    fp = cases['false_positive'] if 'false_positive' in cases else 0\n","    fn = cases['false_negative'] if 'false_negative' in cases else 0\n","    return (tp + tn) / (tp+tn+fp+fn) if (tp+tn+fp+fn) != 0 else 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2ZglF8TVD2uL","colab_type":"code","outputId":"185296fb-0fe0-4bb3-a36f-2ff83ae3dba5","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1549843024134,"user_tz":480,"elapsed":278,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#test\n","\n","print(('should be 0', accuracy(pd.Series({}))))\n","print(('should be 0.3', accuracy(pd.Series({'true_positive':1, 'true_negative':2, 'false_positive':3, 'false_negative':4}))))\n","print(('should be 0.2', accuracy(pd.Series({'true_negative':2, 'false_positive':3, 'false_negative':4}))))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["('should be 0', 0)\n","('should be 0.3', 0.3)\n","('should be 0.2', 0.2222222222222222)\n"],"name":"stdout"}]},{"metadata":{"id":"Vgxs3CQHFGCX","colab_type":"code","colab":{}},"cell_type":"code","source":["def f1(cases):\n","    #the heart of the matrix\n","    tp = cases['true_positive'] if 'true_positive' in cases else 0\n","    tn = cases['true_negative'] if 'true_negative' in cases else 0\n","    fp = cases['false_positive'] if 'false_positive' in cases else 0\n","    fn = cases['false_negative'] if 'false_negative' in cases else 0\n","    \n","    #other measures we can derive\n","    recall = 1.0*tp / (tp+fn) if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\n","    precision = 1.0*tp / (tp+fp) if (tp+fp) != 0 else 0 # positive correct divided by all positive predictions made\n","    \n","    #now for the one we want\n","    term1 = 1 / recall if recall != 0 else 0\n","    term2 = 1 / precision if precision != 0 else 0\n","    f1 = 2 / (term1 + term2) if term1 + term2 != 0 else 0\n","    \n","    return f1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YOjhyJYhGPt0","colab_type":"code","outputId":"017ac7a2-b825-4c76-dee2-2c071d6697dc","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1549843025053,"user_tz":480,"elapsed":786,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#test\n","\n","print(('should be 0', f1(pd.Series({}))))\n","print(('should be 0.2', f1(pd.Series({'true_positive':1, 'true_negative':2, 'false_positive':3, 'false_negative':4}))))\n","print(('should be 0', f1(pd.Series({'true_negative':2, 'false_positive':3, 'false_negative':4}))))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["('should be 0', 0)\n","('should be 0.2', 0.2222222222222222)\n","('should be 0', 0)\n"],"name":"stdout"}]},{"metadata":{"id":"GQQ2BqeXHNDI","colab_type":"code","colab":{}},"cell_type":"code","source":["def informedness(cases):\n","    tp = cases['true_positive'] if 'true_positive' in cases else 0\n","    tn = cases['true_negative'] if 'true_negative' in cases else 0\n","    fp = cases['false_positive'] if 'false_positive' in cases else 0\n","    fn = cases['false_negative'] if 'false_negative' in cases else 0\n","    recall = 1.0*tp / (tp+fn) if (tp+fn) != 0 else 0  # positive correct divided by total positive in the table\n","    specificty = 1.0*tn/(tn+fp) if (tn+fp) != 0 else 0 # negative correct divided by total negative in the table\n","    J = (recall + specificty) - 1\n","    return J"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MMM0Etf5Hkgc","colab_type":"code","outputId":"ab9b598c-dc38-4092-d659-eec46143c0c4","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1549843025298,"user_tz":480,"elapsed":458,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#test\n","\n","print(('should be -1', informedness(pd.Series({}))))\n","print(('should be -0.39', informedness(pd.Series({'true_positive':1, 'true_negative':2, 'false_positive':3, 'false_negative':4}))))\n","print(('should be -0.6', informedness(pd.Series({'true_negative':2, 'false_positive':3, 'false_negative':4}))))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["('should be -1', -1)\n","('should be -0.39', -0.3999999999999999)\n","('should be -0.6', -0.6)\n"],"name":"stdout"}]},{"metadata":{"id":"yfjDiH1-gHKG","colab_type":"text"},"cell_type":"markdown","source":["<h1>Ok, now update your library</h1>\n","When you have done that, you are ready to import.\n","<p>\n","  <b>Important note</b>: you may be tempted to skip the step of updating your library before importing. Why do that when you already have the new functions defined above? We are back to that static-scope thing. Your notebook context (namespace) can see your library functions but your library functions cannot see your notebook functions. The library has its own namespace. In summary, `produce_scores` will not see your functions above. Instead it will see the functions in your library. And if you don't update your library, you will be using your old, broken versions. And it does not matter if you import first then define new functions in the notebook. Your notebook functions still will not override your library functions. Whew. So go update your library!"]},{"metadata":{"id":"YA2LVL6j6uPT","colab_type":"code","colab":{}},"cell_type":"code","source":["!rm library_w19_week5.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oy4fWQH47nfH","colab_type":"code","outputId":"3fb488e6-c2de-4664-d779-5f87ed2e1821","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1549843031708,"user_tz":480,"elapsed":4251,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-502a08b9-4ccf-488b-9b9c-4a43b5892169\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-502a08b9-4ccf-488b-9b9c-4a43b5892169\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving library_w19_week5.py to library_w19_week5.py\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'library_w19_week5.py': b'from functools import reduce\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\nfrom types import SimpleNamespace\\r\\n\\r\\ndef predictor_case(row, pred, target):\\r\\n  case_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\r\\n  actual = row[target]\\r\\n  prediction = row[pred]\\r\\n  case = case_dict[(prediction, actual)]\\r\\n  return case\\r\\n\\r\\ndef accuracy(cases):\\r\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\r\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\r\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\r\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\r\\n    return (tp + tn) / (tp+tn+fp+fn) if (tp+tn+fp+fn) != 0 else 0\\r\\n\\r\\ndef f1(cases):\\r\\n    #the heart of the matrix\\r\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\r\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\r\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\r\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\r\\n    \\r\\n    #other measures we can derive\\r\\n    recall = 1.0*tp / (tp+fn) if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\\r\\n    precision = 1.0*tp / (tp+fp) if (tp+fp) != 0 else 0 # positive correct divided by all positive predictions made\\r\\n    \\r\\n    #now for the one we want\\r\\n    term1 = 1 / recall if recall != 0 else 0\\r\\n    term2 = 1 / precision if precision != 0 else 0\\r\\n    f1 = 2 / (term1 + term2) if term1 + term2 != 0 else 0\\r\\n    \\r\\n    return f1\\r\\n\\r\\ndef informedness(cases):\\r\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\r\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\r\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\r\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\r\\n    recall = 1.0*tp / (tp+fn) if (tp+fn) != 0 else 0  # positive correct divided by total positive in the table\\r\\n    specificty = 1.0*tn/(tn+fp) if (tn+fp) != 0 else 0 # negative correct divided by total negative in the table\\r\\n    J = (recall + specificty) - 1\\r\\n    return J\\r\\n\\r\\ndef probabilities(counts):\\r\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\r\\n    count_1 = 0 if 1 not in counts else counts[1]\\r\\n    total = count_0 + count_1\\r\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\r\\n    return probs\\r\\n\\r\\ndef gini(counts):\\r\\n    (p0,p1) = probabilities(counts)\\r\\n    sum_probs = p0**2 + p1**2\\r\\n    gini = 1 - sum_probs\\r\\n    return gini\\r\\n\\r\\ndef gig(starting_table, split_column, target_column):\\r\\n    \\r\\n    #split into two branches, i.e., two sub-tables\\r\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\r\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\r\\n    \\r\\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\r\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\r\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\r\\n    starting_counts = starting_table[target_column].value_counts() \\r\\n    \\r\\n    #compute the gini impurity for the 3 tables\\r\\n    starting_gini = gini(starting_counts)\\r\\n    true_gini = gini(true_counts)\\r\\n    false_gini = gini(false_counts)\\r\\n\\r\\n    #compute the weights\\r\\n    starting_size = len(starting_table.index)\\r\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\r\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\r\\n    \\r\\n    #wrap it up and put on a bow\\r\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\r\\n    \\r\\n    return gig\\r\\n\\r\\ndef build_pred(column, branch):\\r\\n    return lambda row: row[column] == branch\\r\\n\\r\\ndef find_best_splitter(table, choice_list, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot split empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\r\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\r\\n    return gig_sorted\\r\\n\\r\\ndef generate_table(table, conjunction):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot generate from empty table\"\\r\\n\\r\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\r\\n    return sub_table\\r\\n\\r\\ndef compute_prediction(table, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot predict from empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\r\\n\\r\\n    if 0 not in counts:\\r\\n        prediction = 1\\r\\n    elif 1 not in counts:\\r\\n        prediction = 0\\r\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\r\\n        prediction = 1\\r\\n    else:\\r\\n        prediction = 0\\r\\n\\r\\n    return prediction\\r\\n\\r\\ndef build_tree_iter(table, choices, target, hypers={} ):\\r\\n\\r\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\r\\n    assert (target in table), \"Target column not in table\"\\r\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\r\\n    \\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    \\r\\n    def iterative_build(k):\\r\\n        columns_sorted = find_best_splitter(table, choices, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n        \\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\r\\n        tree_paths = []  # add completed paths here\\r\\n        \\r\\n        while k>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\r\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n            \\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                k -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunction = path[\\'conjunction\\']\\r\\n            before_table = generate_table(table, conjunction)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return tree_paths\\r\\n\\r\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\r\\n\\r\\ndef tree_predictor(row, tree):\\r\\n    \\r\\n    #go through each path, one by one (could use a map instead of for loop?)\\r\\n    for path in tree[\\'paths\\']:\\r\\n        conjuncts = path[\\'conjunction\\']\\r\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n        if all(result):\\r\\n            return path[\\'prediction\\']\\r\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\r\\n\\r\\ndef path_id(row, tree):\\r\\n  \\r\\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\r\\n    \\r\\n    for idx,path in enumerate(tree[\\'paths\\']):\\r\\n      conjuncts = path[\\'conjunction\\']\\r\\n      result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n      if all(result):\\r\\n        return idx\\r\\n\\r\\ndef reorder_paths(table, tree):\\r\\n  pcounts = table.apply(lambda row: path_id(row, tree), axis = 1)\\r\\n  pdict = dict(pcounts.value_counts())\\r\\n  plist = [(key, pdict[key]) for key in pdict]\\r\\n  plist = sorted(plist, key = lambda tup: tup[1])[::-1]\\r\\n  \\r\\n  new_paths = []\\r\\n  for tup in plist:\\r\\n    new_paths.append(tree[\\'paths\\'][tup[0]])\\r\\n    \\r\\n  return new_paths\\r\\n\\r\\ndef produce_scores(table, tree, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef compute_training(slices, left_out):\\r\\n    training_slices = []\\r\\n    for i,slice in enumerate(slices):\\r\\n        if i == left_out:\\r\\n            continue\\r\\n        training_slices.append(slices[i])\\r\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\r\\n\\r\\ndef k_fold(table, k, target, hypers, candidate_columns):\\r\\n  \\r\\n    #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    for i in range(k-1):\\r\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n        slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n'}"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"NKKiXDAP72Cs","colab_type":"code","outputId":"977c28a9-4605-453d-fda9-80083ebded1b","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1549843034501,"user_tz":480,"elapsed":302,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["from library_w19_week5 import *\n","\n","%who function"],"execution_count":12,"outputs":[{"output_type":"stream","text":["accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t f1\t find_best_splitter\t generate_table\t gig\t \n","gini\t informedness\t k_fold\t path_id\t predictor_case\t probabilities\t produce_scores\t reorder_paths\t tree_predictor\t \n","\n"],"name":"stdout"}]},{"metadata":{"id":"Z6qJLQjp6uPv","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","2: Explore depth parameter with 10-folding (10 points)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","In the week 4 module you were asked to explore depths from 1 to 5 without any cross-validation. Go ahead and do it again but using K-folding with K=10.\n","<p>\n","First, define the columns to use. I do that for you below.\n","</div>"]},{"metadata":{"id":"OdL8BLMW6uPw","colab_type":"code","colab":{}},"cell_type":"code","source":["splitter_columns = [\n","        #ApplicantIncome\n","       'apin_low', 'apin_high', 'apin_average',\n","        #Property_Area\n","        'pa_Rural', 'pa_Semiurban','pa_Urban',\n","        #LoanAmount\n","        'lam_Low', 'lam_Average', 'lam_High',\n","        #Credit_History\n","        'ch_bad', 'ch_good']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Iut2ZAKT6uP0","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h2>\n","Show your results below\n","</h2>\n","<p>\n","<div class=h1_cell>\n","<p>\n","Explore depths 1-5 with 10-folding. You can leave the gig cutoff as default value.\n","</div>"]},{"metadata":{"id":"87IS1HvC6uP6","colab_type":"code","outputId":"5882e017-8e20-4132-ec85-abdca56187de","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1549843037822,"user_tz":480,"elapsed":855,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["table10_1 = k_fold(loan_table, 10, 'Loan_Status', {'max-depth':1}, splitter_columns)\n","table10_1"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.770492</td>\n","      <td>0.847826</td>\n","      <td>0.363636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.852459</td>\n","      <td>0.905263</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.754098</td>\n","      <td>0.835165</td>\n","      <td>0.330952</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.770492</td>\n","      <td>0.860000</td>\n","      <td>0.212567</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.365633</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.803279</td>\n","      <td>0.877551</td>\n","      <td>0.330214</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.836066</td>\n","      <td>0.886364</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.868852</td>\n","      <td>0.914894</td>\n","      <td>0.565508</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.786885</td>\n","      <td>0.865979</td>\n","      <td>0.310078</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.846154</td>\n","      <td>0.895833</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.809206</td>\n","      <td>0.876388</td>\n","      <td>0.406950</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.770492  0.847826      0.363636\n","1    fold_1  0.852459  0.905263      0.500000\n","2    fold_2  0.754098  0.835165      0.330952\n","3    fold_3  0.770492  0.860000      0.212567\n","4    fold_4  0.803279  0.875000      0.365633\n","5    fold_5  0.803279  0.877551      0.330214\n","6    fold_6  0.836066  0.886364      0.545455\n","7    fold_7  0.868852  0.914894      0.565508\n","8    fold_8  0.786885  0.865979      0.310078\n","9    fold_9  0.846154  0.895833      0.545455\n","10  average  0.809206  0.876388      0.406950"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"OaQ698XY6uQA","colab_type":"code","outputId":"183ee102-b6c9-4988-b9ee-5279c284ff12","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1549843110173,"user_tz":480,"elapsed":1485,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["table10_2 = k_fold(loan_table, 10, 'Loan_Status', {'max-depth':2}, splitter_columns)\n","table10_2"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.770492</td>\n","      <td>0.847826</td>\n","      <td>0.363636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.852459</td>\n","      <td>0.905263</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.754098</td>\n","      <td>0.835165</td>\n","      <td>0.330952</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.770492</td>\n","      <td>0.860000</td>\n","      <td>0.212567</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.365633</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.803279</td>\n","      <td>0.877551</td>\n","      <td>0.330214</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.819672</td>\n","      <td>0.876404</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.868852</td>\n","      <td>0.914894</td>\n","      <td>0.565508</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.786885</td>\n","      <td>0.865979</td>\n","      <td>0.310078</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.846154</td>\n","      <td>0.895833</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.807566</td>\n","      <td>0.875392</td>\n","      <td>0.402404</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.770492  0.847826      0.363636\n","1    fold_1  0.852459  0.905263      0.500000\n","2    fold_2  0.754098  0.835165      0.330952\n","3    fold_3  0.770492  0.860000      0.212567\n","4    fold_4  0.803279  0.875000      0.365633\n","5    fold_5  0.803279  0.877551      0.330214\n","6    fold_6  0.819672  0.876404      0.500000\n","7    fold_7  0.868852  0.914894      0.565508\n","8    fold_8  0.786885  0.865979      0.310078\n","9    fold_9  0.846154  0.895833      0.545455\n","10  average  0.807566  0.875392      0.402404"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"fe9hIraT6uQH","colab_type":"code","outputId":"44dfe70f-7ea6-4aba-9483-d0eb8f290025","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1549843180042,"user_tz":480,"elapsed":2871,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["table10_3 = k_fold(loan_table, 10, 'Loan_Status', {'max-depth':3}, splitter_columns)\n","table10_3"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.770492</td>\n","      <td>0.847826</td>\n","      <td>0.363636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.852459</td>\n","      <td>0.905263</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.721311</td>\n","      <td>0.808989</td>\n","      <td>0.280952</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.770492</td>\n","      <td>0.860000</td>\n","      <td>0.212567</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.365633</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.803279</td>\n","      <td>0.877551</td>\n","      <td>0.330214</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.819672</td>\n","      <td>0.876404</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.868852</td>\n","      <td>0.914894</td>\n","      <td>0.565508</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.786885</td>\n","      <td>0.865979</td>\n","      <td>0.310078</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.846154</td>\n","      <td>0.895833</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.804288</td>\n","      <td>0.872774</td>\n","      <td>0.397404</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.770492  0.847826      0.363636\n","1    fold_1  0.852459  0.905263      0.500000\n","2    fold_2  0.721311  0.808989      0.280952\n","3    fold_3  0.770492  0.860000      0.212567\n","4    fold_4  0.803279  0.875000      0.365633\n","5    fold_5  0.803279  0.877551      0.330214\n","6    fold_6  0.819672  0.876404      0.500000\n","7    fold_7  0.868852  0.914894      0.565508\n","8    fold_8  0.786885  0.865979      0.310078\n","9    fold_9  0.846154  0.895833      0.545455\n","10  average  0.804288  0.872774      0.397404"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"U5_csX796uQN","colab_type":"code","outputId":"71354a67-15c8-4bdd-dd77-29509b57ac90","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1549843190600,"user_tz":480,"elapsed":4937,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["table10_4 = k_fold(loan_table, 10, 'Loan_Status', {'max-depth':4}, splitter_columns)\n","table10_4"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.770492</td>\n","      <td>0.847826</td>\n","      <td>0.363636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.852459</td>\n","      <td>0.905263</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.737705</td>\n","      <td>0.822222</td>\n","      <td>0.305952</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.770492</td>\n","      <td>0.860000</td>\n","      <td>0.212567</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.365633</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.366310</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.819672</td>\n","      <td>0.876404</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.868852</td>\n","      <td>0.914894</td>\n","      <td>0.565508</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.786885</td>\n","      <td>0.865979</td>\n","      <td>0.310078</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.846154</td>\n","      <td>0.895833</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.805927</td>\n","      <td>0.873842</td>\n","      <td>0.403514</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.770492  0.847826      0.363636\n","1    fold_1  0.852459  0.905263      0.500000\n","2    fold_2  0.737705  0.822222      0.305952\n","3    fold_3  0.770492  0.860000      0.212567\n","4    fold_4  0.803279  0.875000      0.365633\n","5    fold_5  0.803279  0.875000      0.366310\n","6    fold_6  0.819672  0.876404      0.500000\n","7    fold_7  0.868852  0.914894      0.565508\n","8    fold_8  0.786885  0.865979      0.310078\n","9    fold_9  0.846154  0.895833      0.545455\n","10  average  0.805927  0.873842      0.403514"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"2FWHU0vR6uQZ","colab_type":"code","outputId":"953156f7-566c-4e18-98ef-7e1f5cc776ff","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1549843204599,"user_tz":480,"elapsed":8529,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["table10_5 = k_fold(loan_table, 10, 'Loan_Status', {'max-depth':5}, splitter_columns)\n","table10_5"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.770492</td>\n","      <td>0.847826</td>\n","      <td>0.363636</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.852459</td>\n","      <td>0.905263</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.754098</td>\n","      <td>0.835165</td>\n","      <td>0.330952</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.770492</td>\n","      <td>0.860000</td>\n","      <td>0.212567</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.365633</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.803279</td>\n","      <td>0.875000</td>\n","      <td>0.366310</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.836066</td>\n","      <td>0.886364</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.868852</td>\n","      <td>0.914894</td>\n","      <td>0.565508</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.754098</td>\n","      <td>0.842105</td>\n","      <td>0.263566</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.846154</td>\n","      <td>0.895833</td>\n","      <td>0.545455</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.805927</td>\n","      <td>0.873745</td>\n","      <td>0.405908</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.770492  0.847826      0.363636\n","1    fold_1  0.852459  0.905263      0.500000\n","2    fold_2  0.754098  0.835165      0.330952\n","3    fold_3  0.770492  0.860000      0.212567\n","4    fold_4  0.803279  0.875000      0.365633\n","5    fold_5  0.803279  0.875000      0.366310\n","6    fold_6  0.836066  0.886364      0.545455\n","7    fold_7  0.868852  0.914894      0.565508\n","8    fold_8  0.754098  0.842105      0.263566\n","9    fold_9  0.846154  0.895833      0.545455\n","10  average  0.805927  0.873745      0.405908"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"onzdITMo6uQf","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","What does it look like to you?\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","To me it looks like the stump is best! As we add depth I don't see an improvement. And it looks like results from depth 4 and 5 the same. What I would try next is the gig cutoff and bringing more columns into play (e.g., Gender, Married) by applying ohe to them.\n","</div>"]},{"metadata":{"id":"8hRUbj7i6uQh","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","4: Random slices (60 points)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","I'd like you to try one more thing. The `k_fold` function takes slices sequentially. I'd like you to write a function `k_fold_random` that takes random slices *without replacement*. Without replacement means that each slice should have a unique set of rows, i.e., no slices share a row\n","<p>\n","Each slice should be roughly 1/k percent of the entire table.\n","<p>\n","To solve this problem, I found it easiest to play around with loops in a notebook cell before trying to replace code in `k_fold`. My target was the equivalent of this but now with random slices:\n","<pre>\n","<code>\n","    total_len = len(table.index)\n","    slice_size = int(total_len/(1.0`*`k))\n","    slices = []\n","\n","    #generate the slices\n","    for i in range(k-1):\n","        a_slice =  table[i`*`slice_size:(i+1)`*`slice_size]\n","        slices.append( a_slice )\n","    slices.append( table[(k-1)`*`slice_size:] )\n","    \n","    verify_unique(slices)  # I ask you to define this debugging function below\n","</code>\n","</pre>\n","<p>\n","I copied this code into a cell and then started to play around with various ideas until I got one I liked.\n","<p>\n","</div>"]},{"metadata":{"id":"2ZFj-lzb_r7I","colab_type":"text"},"cell_type":"markdown","source":["<h2>Help with debugging</h2>\n","I'll define a debugging function that will take a list of slices and do a pairwise comparison. For each pair, it will print the set intersection between the 2 slices. I give you a few test cases to try."]},{"metadata":{"id":"4vKnpmzU6uQi","colab_type":"code","colab":{}},"cell_type":"code","source":["#Determine if slices are mutually exclusive\n","def verify_unique(slices):\n","    print(('total length all slices', sum([len(s) for s in slices])))\n","    for i, a_slice in enumerate(slices[:-1]):\n","        a_set = set(a_slice.index)\n","        for j, b_slice in enumerate(slices[i+1:]):\n","            b_set = set(b_slice.index)\n","            int_set = a_set.intersection(b_set)  # should be empty set as result\n","            print((i,j+i+1,int_set))\n","    return None"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B39CV9Zz6uQl","colab_type":"code","outputId":"277951ed-ad26-43ef-bfd9-2df018f67013","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1549844947568,"user_tz":480,"elapsed":309,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#test\n","\n","verify_unique([loan_table[0:2], loan_table[2:4], loan_table[4:5]])  #looks good - enpty set for each pair"],"execution_count":20,"outputs":[{"output_type":"stream","text":["('total length all slices', 5)\n","(0, 1, set())\n","(0, 2, set())\n","(1, 2, set())\n"],"name":"stdout"}]},{"metadata":{"id":"OnanZoGm_PSP","colab_type":"code","outputId":"d0042a37-ae93-44f0-98a0-9e44c1a1ccd7","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1549844958130,"user_tz":480,"elapsed":302,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["#test\n","\n","verify_unique([loan_table[0:2], loan_table[1:4], loan_table[1:5]])  #not so good, finds intersection between all 3 pairs"],"execution_count":21,"outputs":[{"output_type":"stream","text":["('total length all slices', 9)\n","(0, 1, {1})\n","(0, 2, {1})\n","(1, 2, {1, 2, 3})\n"],"name":"stdout"}]},{"metadata":{"id":"u4_VZceV6uQt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":815},"outputId":"5a9e7024-0818-434f-f22e-a190cc426df6","executionInfo":{"status":"ok","timestamp":1549848187223,"user_tz":480,"elapsed":2668,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["# here is sequential slice code from k_fold if you want to use it as base.\n","# modify it to produce slices with random rows in each slice.\n","import random\n","\n","table = loan_table\n","k = 10\n","\n","total_len = len(table.index)\n","split_size = int(total_len/(1.0*k))\n","slices = []\n","available_rows = [i for i in range(total_len)] # we will pick a random row from here\n","\n","#generate the slices\n","for i in range(k):\n","  a_slice = pd.DataFrame(columns=table.columns)\n","  \n","  for j in range(split_size):\n","    rand_idx = random.randint(0, len(available_rows) - 1)\n","    idx = available_rows[rand_idx] # which row we want to grab\n","    a_slice = a_slice.append(table[idx:idx+1], ignore_index=False) # add random row to current slice\n","    available_rows.remove(idx) # remove that row from the available rows\n","  \n","  slices.append( a_slice )\n","\n","for remaining_idx in available_rows: # add the remaining rows to our final slice\n","  slices[len(slices) - 1] = slices[len(slices) - 1].append(table[remaining_idx:remaining_idx+1], ignore_index=False)\n","  \n","verify_unique(slices)  # should see 614 length and empty sets all the way down"],"execution_count":96,"outputs":[{"output_type":"stream","text":["('total length all slices', 614)\n","(0, 1, set())\n","(0, 2, set())\n","(0, 3, set())\n","(0, 4, set())\n","(0, 5, set())\n","(0, 6, set())\n","(0, 7, set())\n","(0, 8, set())\n","(0, 9, set())\n","(1, 2, set())\n","(1, 3, set())\n","(1, 4, set())\n","(1, 5, set())\n","(1, 6, set())\n","(1, 7, set())\n","(1, 8, set())\n","(1, 9, set())\n","(2, 3, set())\n","(2, 4, set())\n","(2, 5, set())\n","(2, 6, set())\n","(2, 7, set())\n","(2, 8, set())\n","(2, 9, set())\n","(3, 4, set())\n","(3, 5, set())\n","(3, 6, set())\n","(3, 7, set())\n","(3, 8, set())\n","(3, 9, set())\n","(4, 5, set())\n","(4, 6, set())\n","(4, 7, set())\n","(4, 8, set())\n","(4, 9, set())\n","(5, 6, set())\n","(5, 7, set())\n","(5, 8, set())\n","(5, 9, set())\n","(6, 7, set())\n","(6, 8, set())\n","(6, 9, set())\n","(7, 8, set())\n","(7, 9, set())\n","(8, 9, set())\n"],"name":"stdout"}]},{"metadata":{"id":"_2N8lTi06uQw","colab_type":"text"},"cell_type":"markdown","source":["<h2>\n","Plug your code in\n","</h2>\n","<p>\n","<div class=h1_cell>\n","<p>\n","Once you are generating slices randomly, you will have k test slices. You can go ahead and place your code into `k_fold_random`. You should now be good to go.\n","<p>\n","One problem with doing random selections is that we will get different results every time we run our code. We will see a way to get repeatable results in next module. For now, you may find that you are not matching my fold results.\n","</div>"]},{"metadata":{"id":"J4dkFQwb6uQw","colab_type":"code","colab":{}},"cell_type":"code","source":["def k_fold_random(table, k, target, hypers, candidate_columns):\n","  \n","    #set up the table where we will record fold results\n","    result_columns = ['name',  'accuracy', 'f1', 'informedness']\n","    k_fold_results_table = pd.DataFrame(columns=result_columns)\n","    \n","    #generate the slices\n","    total_len = len(table.index)\n","    split_size = int(total_len/(1.0*k))\n","    slices = []\n","    available_rows = [i for i in range(total_len)] # we will pick a random row from here\n","\n","    for i in range(k):\n","      a_slice = pd.DataFrame(columns=table.columns)\n","\n","      for j in range(split_size):\n","        rand_idx = random.randint(0, len(available_rows) - 1)\n","        idx = available_rows[rand_idx] # which row we want to grab\n","        a_slice = a_slice.append(table[idx:idx+1], ignore_index=False) # add random row to current slice\n","        available_rows.remove(idx) # remove that row from the available rows\n","\n","      slices.append( a_slice )\n","\n","    for remaining_idx in available_rows: # add the remaining rows to our final slice\n","      slices[len(slices) - 1] = slices[len(slices) - 1].append(table[remaining_idx:remaining_idx+1], ignore_index=False)\n","      \n","    verify_unique(slices)  # leaving this in here to verify it is working\n","    \n","    #generate test results\n","    all_scores = []  #keep track of all k results\n","    for i in range(k):\n","        test_table = slices[i]\n","        train_table = compute_training(slices, i)\n","        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\n","        scores = produce_scores(test_table, fold_tree, target)  # test\n","        results_row = {'name': 'fold_'+str(i), 'accuracy': scores[0], 'f1': scores[1], 'informedness': scores[2]}\n","        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\n","        all_scores.append(scores)\n","    \n","    #compute average of all folds\n","    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\n","    results_row = {'name': 'average', 'accuracy': avg_scores[0], 'f1': avg_scores[1], 'informedness': avg_scores[2]}\n","    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\n","    \n","    #note that I add the meta comment as last step to avoid it being wiped out\n","    k_fold_results_table.meta = SimpleNamespace()\n","    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\n","    \n","    return k_fold_results_table\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JgzsHe8z6uQ0","colab_type":"code","outputId":"fa248982-7f19-461c-eb6f-afff755baf6a","colab":{"base_uri":"https://localhost:8080/","height":1183},"executionInfo":{"status":"ok","timestamp":1549848346680,"user_tz":480,"elapsed":3099,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["k_fold_random(loan_table, 10, 'Loan_Status', {'max-depth': 1}, splitter_columns)"],"execution_count":102,"outputs":[{"output_type":"stream","text":["('total length all slices', 614)\n","(0, 1, set())\n","(0, 2, set())\n","(0, 3, set())\n","(0, 4, set())\n","(0, 5, set())\n","(0, 6, set())\n","(0, 7, set())\n","(0, 8, set())\n","(0, 9, set())\n","(1, 2, set())\n","(1, 3, set())\n","(1, 4, set())\n","(1, 5, set())\n","(1, 6, set())\n","(1, 7, set())\n","(1, 8, set())\n","(1, 9, set())\n","(2, 3, set())\n","(2, 4, set())\n","(2, 5, set())\n","(2, 6, set())\n","(2, 7, set())\n","(2, 8, set())\n","(2, 9, set())\n","(3, 4, set())\n","(3, 5, set())\n","(3, 6, set())\n","(3, 7, set())\n","(3, 8, set())\n","(3, 9, set())\n","(4, 5, set())\n","(4, 6, set())\n","(4, 7, set())\n","(4, 8, set())\n","(4, 9, set())\n","(5, 6, set())\n","(5, 7, set())\n","(5, 8, set())\n","(5, 9, set())\n","(6, 7, set())\n","(6, 8, set())\n","(6, 9, set())\n","(7, 8, set())\n","(7, 9, set())\n","(8, 9, set())\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.803279</td>\n","      <td>0.866667</td>\n","      <td>0.454545</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.819672</td>\n","      <td>0.888889</td>\n","      <td>0.352778</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.754098</td>\n","      <td>0.827586</td>\n","      <td>0.382151</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.803279</td>\n","      <td>0.866667</td>\n","      <td>0.451190</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.868852</td>\n","      <td>0.921569</td>\n","      <td>0.428571</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.770492</td>\n","      <td>0.851064</td>\n","      <td>0.325610</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.836066</td>\n","      <td>0.888889</td>\n","      <td>0.525610</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.803279</td>\n","      <td>0.869565</td>\n","      <td>0.428571</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.836066</td>\n","      <td>0.895833</td>\n","      <td>0.447861</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.800000</td>\n","      <td>0.878505</td>\n","      <td>0.277778</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.809508</td>\n","      <td>0.875523</td>\n","      <td>0.407467</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.803279  0.866667      0.454545\n","1    fold_1  0.819672  0.888889      0.352778\n","2    fold_2  0.754098  0.827586      0.382151\n","3    fold_3  0.803279  0.866667      0.451190\n","4    fold_4  0.868852  0.921569      0.428571\n","5    fold_5  0.770492  0.851064      0.325610\n","6    fold_6  0.836066  0.888889      0.525610\n","7    fold_7  0.803279  0.869565      0.428571\n","8    fold_8  0.836066  0.895833      0.447861\n","9    fold_9  0.800000  0.878505      0.277778\n","10  average  0.809508  0.875523      0.407467"]},"metadata":{"tags":[]},"execution_count":102}]},{"metadata":{"id":"eCRnBm7yLs6n","colab_type":"text"},"cell_type":"markdown","source":["What we got with prior sequential split at depth 1: \n","<pre>\n","10\taverage\t0.809206\t0.876388\t0.406950\n","</pre>"]},{"metadata":{"id":"Ymk6TWaf6uQ3","colab_type":"code","outputId":"a5912e41-fe86-48a8-c8cc-a23b892554fb","colab":{"base_uri":"https://localhost:8080/","height":1183},"executionInfo":{"status":"ok","timestamp":1549848364819,"user_tz":480,"elapsed":3935,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["k_fold_random(loan_table, 10, 'Loan_Status', {'max-depth': 2}, splitter_columns)"],"execution_count":103,"outputs":[{"output_type":"stream","text":["('total length all slices', 614)\n","(0, 1, set())\n","(0, 2, set())\n","(0, 3, set())\n","(0, 4, set())\n","(0, 5, set())\n","(0, 6, set())\n","(0, 7, set())\n","(0, 8, set())\n","(0, 9, set())\n","(1, 2, set())\n","(1, 3, set())\n","(1, 4, set())\n","(1, 5, set())\n","(1, 6, set())\n","(1, 7, set())\n","(1, 8, set())\n","(1, 9, set())\n","(2, 3, set())\n","(2, 4, set())\n","(2, 5, set())\n","(2, 6, set())\n","(2, 7, set())\n","(2, 8, set())\n","(2, 9, set())\n","(3, 4, set())\n","(3, 5, set())\n","(3, 6, set())\n","(3, 7, set())\n","(3, 8, set())\n","(3, 9, set())\n","(4, 5, set())\n","(4, 6, set())\n","(4, 7, set())\n","(4, 8, set())\n","(4, 9, set())\n","(5, 6, set())\n","(5, 7, set())\n","(5, 8, set())\n","(5, 9, set())\n","(6, 7, set())\n","(6, 8, set())\n","(6, 9, set())\n","(7, 8, set())\n","(7, 9, set())\n","(8, 9, set())\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.803279</td>\n","      <td>0.872340</td>\n","      <td>0.397243</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.786885</td>\n","      <td>0.868687</td>\n","      <td>0.277778</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.786885</td>\n","      <td>0.868687</td>\n","      <td>0.271390</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.852459</td>\n","      <td>0.901099</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.786885</td>\n","      <td>0.863158</td>\n","      <td>0.342377</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.754098</td>\n","      <td>0.848485</td>\n","      <td>0.198966</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.868852</td>\n","      <td>0.918367</td>\n","      <td>0.511594</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.885246</td>\n","      <td>0.919540</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.803279</td>\n","      <td>0.869565</td>\n","      <td>0.428571</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.753846</td>\n","      <td>0.829787</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.808172</td>\n","      <td>0.875972</td>\n","      <td>0.401959</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.803279  0.872340      0.397243\n","1    fold_1  0.786885  0.868687      0.277778\n","2    fold_2  0.786885  0.868687      0.271390\n","3    fold_3  0.852459  0.901099      0.550000\n","4    fold_4  0.786885  0.863158      0.342377\n","5    fold_5  0.754098  0.848485      0.198966\n","6    fold_6  0.868852  0.918367      0.511594\n","7    fold_7  0.885246  0.919540      0.666667\n","8    fold_8  0.803279  0.869565      0.428571\n","9    fold_9  0.753846  0.829787      0.375000\n","10  average  0.808172  0.875972      0.401959"]},"metadata":{"tags":[]},"execution_count":103}]},{"metadata":{"id":"xtgk7PomMKEt","colab_type":"text"},"cell_type":"markdown","source":["What we got in sequential at depth 2:\n","<pre>\n","10\taverage\t0.807566\t0.875392\t0.402404\n","</pre>\n","Let's try one more."]},{"metadata":{"id":"fUl9_QCa6uQ6","colab_type":"code","outputId":"e7532711-95b4-4609-f6e5-9aea862c8245","colab":{"base_uri":"https://localhost:8080/","height":1183},"executionInfo":{"status":"ok","timestamp":1549848378177,"user_tz":480,"elapsed":5347,"user":{"displayName":"Andrew Letz","photoUrl":"","userId":"01040931929943944952"}}},"cell_type":"code","source":["k_fold_random(loan_table, 10, 'Loan_Status', {'max-depth': 3}, splitter_columns)"],"execution_count":104,"outputs":[{"output_type":"stream","text":["('total length all slices', 614)\n","(0, 1, set())\n","(0, 2, set())\n","(0, 3, set())\n","(0, 4, set())\n","(0, 5, set())\n","(0, 6, set())\n","(0, 7, set())\n","(0, 8, set())\n","(0, 9, set())\n","(1, 2, set())\n","(1, 3, set())\n","(1, 4, set())\n","(1, 5, set())\n","(1, 6, set())\n","(1, 7, set())\n","(1, 8, set())\n","(1, 9, set())\n","(2, 3, set())\n","(2, 4, set())\n","(2, 5, set())\n","(2, 6, set())\n","(2, 7, set())\n","(2, 8, set())\n","(2, 9, set())\n","(3, 4, set())\n","(3, 5, set())\n","(3, 6, set())\n","(3, 7, set())\n","(3, 8, set())\n","(3, 9, set())\n","(4, 5, set())\n","(4, 6, set())\n","(4, 7, set())\n","(4, 8, set())\n","(4, 9, set())\n","(5, 6, set())\n","(5, 7, set())\n","(5, 8, set())\n","(5, 9, set())\n","(6, 7, set())\n","(6, 8, set())\n","(6, 9, set())\n","(7, 8, set())\n","(7, 9, set())\n","(8, 9, set())\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","      <th>informedness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fold_0</td>\n","      <td>0.721311</td>\n","      <td>0.808989</td>\n","      <td>0.320000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fold_1</td>\n","      <td>0.803279</td>\n","      <td>0.872340</td>\n","      <td>0.397243</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fold_2</td>\n","      <td>0.836066</td>\n","      <td>0.897959</td>\n","      <td>0.411765</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>fold_3</td>\n","      <td>0.803279</td>\n","      <td>0.872340</td>\n","      <td>0.400000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fold_4</td>\n","      <td>0.885246</td>\n","      <td>0.932039</td>\n","      <td>0.479592</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>fold_5</td>\n","      <td>0.868852</td>\n","      <td>0.913043</td>\n","      <td>0.578947</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fold_6</td>\n","      <td>0.786885</td>\n","      <td>0.865979</td>\n","      <td>0.307487</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fold_7</td>\n","      <td>0.754098</td>\n","      <td>0.842105</td>\n","      <td>0.275610</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fold_8</td>\n","      <td>0.819672</td>\n","      <td>0.876404</td>\n","      <td>0.498810</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fold_9</td>\n","      <td>0.800000</td>\n","      <td>0.865979</td>\n","      <td>0.431290</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>average</td>\n","      <td>0.807869</td>\n","      <td>0.874718</td>\n","      <td>0.410074</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       name  accuracy        f1  informedness\n","0    fold_0  0.721311  0.808989      0.320000\n","1    fold_1  0.803279  0.872340      0.397243\n","2    fold_2  0.836066  0.897959      0.411765\n","3    fold_3  0.803279  0.872340      0.400000\n","4    fold_4  0.885246  0.932039      0.479592\n","5    fold_5  0.868852  0.913043      0.578947\n","6    fold_6  0.786885  0.865979      0.307487\n","7    fold_7  0.754098  0.842105      0.275610\n","8    fold_8  0.819672  0.876404      0.498810\n","9    fold_9  0.800000  0.865979      0.431290\n","10  average  0.807869  0.874718      0.410074"]},"metadata":{"tags":[]},"execution_count":104}]},{"metadata":{"id":"CI5vixoGNGYA","colab_type":"text"},"cell_type":"markdown","source":["What we got in sequential at depth 3:\n","<pre>\n","10\taverage\t0.804288\t0.872774\t0.397404\n","</pre>\n","Random looks very close to sequential. With this small a dataset, I could see that happening. In general, random is prefered. With sequential you might be picking up some funny ordering of the rows. Maybe they listed the best applicants first."]},{"metadata":{"collapsed":true,"id":"R2CUaYb26uRI","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>Did not change loan table</h1>\n","<div class=h1_cell>\n","<p>\n","No need to write it out.\n","</div>"]},{"metadata":{"id":"uosFosUkPydB","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>We did change library</h1>\n","<div class=h1_cell>\n","<p>\n","We added `verify_unique` and `k_fold_random`. Add them to your library and call new file `library_w19_5b.py`. I added the `b` to differentiate it from functions we added in intro notebook and top of this one.\n","</div>"]},{"metadata":{"id":"cErmWPPZmgig","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}